{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./data/data_pca_50_y_mean.pickle.npz')\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['arr_0']\n",
    "y = data['arr_1']\n",
    "mean = data['arr_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify=y)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C=1.0,kernel='rbf',gamma=0.01,probability=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train)\n",
    "print('model trained sucessfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score\n",
    "model.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "- Confusion Matrix\n",
    "- Classification Report \n",
    "- Kappa Score\n",
    "- ROC and AUC (probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_prob = model.predict_proba(x_test) # proability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test,y_pred)\n",
    "cm = np.concatenate((cm,cm.sum(axis=0).reshape(1,-1)),axis=0)\n",
    "cm = np.concatenate((cm,cm.sum(axis=1).reshape(-1,1)),axis=1)\n",
    "plt.imshow(cm)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plt.text(j,i,'%d'%cm[i,j])\n",
    "        \n",
    "plt.xticks([0,1])\n",
    "plt.yticks([0,1])\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('True Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "cr = metrics.classification_report(y_test,y_pred,target_names=['male','female'],output_dict=True)\n",
    "pd.DataFrame(cr).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kappa\n",
    "metrics.cohen_kappa_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc for female\n",
    "fpr,tpr,thresh = metrics.roc_curve(y_test,y_prob[:,1])\n",
    "auc_s = metrics.auc(fpr,tpr)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(fpr,tpr,'-.')\n",
    "plt.plot([0,1],[0,1],'b--')\n",
    "for i in range(0,len(thresh),20):\n",
    "    plt.plot(fpr[i],tpr[i],'^')\n",
    "    plt.text(fpr[i],tpr[i],\"%0.2f\"%thresh[i])\n",
    "    \n",
    "plt.legend(['AUC Score = %0.2f'%auc_s])\n",
    "\n",
    "plt.xlabel('False Positve Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characterstics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tune = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[1,10,20,30,50,100],\n",
    "             'kernel':['rbf','poly'],\n",
    "             'gamma':[0.1,0.05,0.01,0.001,0.002,0.005],\n",
    "             'coef0':[0,1],\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = GridSearchCV(model_tune,param_grid=param_grid,scoring='accuracy',cv=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIth best parameter buil ML Model\n",
    "model_best = SVC(C=30,kernel='rbf',gamma=0.002,probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.fit(x_train,y_train)\n",
    "model_best.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_best.predict(x_test)\n",
    "y_prob = model_best.predict_proba(x_test) # proability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test,y_pred)\n",
    "cm = np.concatenate((cm,cm.sum(axis=0).reshape(1,-1)),axis=0)\n",
    "cm = np.concatenate((cm,cm.sum(axis=1).reshape(-1,1)),axis=1)\n",
    "plt.imshow(cm)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plt.text(j,i,'%d'%cm[i,j])\n",
    "        \n",
    "plt.xticks([0,1])\n",
    "plt.yticks([0,1])\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('True Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "cr = metrics.classification_report(y_test,y_pred,target_names=['male','female'],output_dict=True)\n",
    "pd.DataFrame(cr).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kappa\n",
    "metrics.cohen_kappa_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc for female\n",
    "fpr,tpr,thresh = metrics.roc_curve(y_test,y_prob[:,1])\n",
    "auc_s = metrics.auc(fpr,tpr)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(fpr,tpr,'-.')\n",
    "plt.plot([0,1],[0,1],'b--')\n",
    "for i in range(0,len(thresh),20):\n",
    "    plt.plot(fpr[i],tpr[i],'^')\n",
    "    plt.text(fpr[i],tpr[i],\"%0.2f\"%thresh[i])\n",
    "    \n",
    "plt.legend(['AUC Score = %0.2f'%auc_s])\n",
    "\n",
    "plt.xlabel('False Positve Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characterstics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our machine learning model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_best,open('./model/model_svm.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mean,open('./model/mean_preprocess.pickle','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
